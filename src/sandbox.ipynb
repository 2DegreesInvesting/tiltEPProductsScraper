{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import unidecode\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import random\n",
    "import codecs\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.dbutils import DBUtils\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databricks file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "dbutils = DBUtils(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_fetcher_per_sector(country=None):\n",
    "    if 'DATABRICKS_RUNTIME_VERSION' in os.environ:\n",
    "        files = [x[0] for x in dbutils.fs.ls(\"abfss://landingzone@storagetiltdevelop.dfs.core.windows.net/tiltEP/\") if f\"/{country}\" in x[0]]\n",
    "    else:\n",
    "        files = [x[0] for x in dbutils.fs.ls(\"abfss:/mnt/indicatorBefore/tiltEP/\") if f\"/{country}\" in x[0]]\n",
    "\n",
    "    out = f\"../input_data/{country}_ids.csv\"\n",
    "    complete_ids = []\n",
    "    for i in range(len(files)):\n",
    "        x = spark.read.csv(files[i],header=True, inferSchema=True, sep=\";\").toPandas()\n",
    "        ids = list(x.drop_duplicates(subset=\"id\")[\"id\"])\n",
    "        complete_ids.append(ids)\n",
    "\n",
    "    complete_ids = list(set([item for sublist in complete_ids for item in sublist]))\n",
    "    complete_ids = pd.DataFrame({'id': complete_ids})\n",
    "    complete_ids.to_csv(out)\n",
    "    return complete_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s-3-srl_seac000145150-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dia-costruzioni-srl_seac005437117-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guerini-paolo_seac000824090-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>studio-tecnico-associato-stf-faccin-arch-a-fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-emme-impianti-srl_seac006235054-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224533</th>\n",
       "      <td>studio-tecnico-navale-ansaldo-snc_seac00279190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224534</th>\n",
       "      <td>agrosun-srl_seac002116524-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224535</th>\n",
       "      <td>sole-edilizia-societa-a-responsabilita-limitat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224536</th>\n",
       "      <td>savini-stefano_seac006037585-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224537</th>\n",
       "      <td>baschieri-rino-di-patrizio-e-dannj-baschieri-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224538 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       id\n",
       "0                               s-3-srl_seac000145150-001\n",
       "1                   dia-costruzioni-srl_seac005437117-001\n",
       "2                         guerini-paolo_seac000824090-001\n",
       "3       studio-tecnico-associato-stf-faccin-arch-a-fac...\n",
       "4                   2-emme-impianti-srl_seac006235054-001\n",
       "...                                                   ...\n",
       "224533  studio-tecnico-navale-ansaldo-snc_seac00279190...\n",
       "224534                      agrosun-srl_seac002116524-001\n",
       "224535  sole-edilizia-societa-a-responsabilita-limitat...\n",
       "224536                   savini-stefano_seac006037585-001\n",
       "224537  baschieri-rino-di-patrizio-e-dannj-baschieri-s...\n",
       "\n",
       "[224538 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_fetcher_per_sector(\"italy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>design-build-modern-stained-glass_000000044107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brent-taxis-cabs_00000005453797-798182001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi-performance-feeds_00000004299041-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>maxiflow-drains_00000004249310-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>simply-frozen_00000004147330-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123960</th>\n",
       "      <td>nwt-distribution-ltd_00000004196560-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123961</th>\n",
       "      <td>jkx-executive-travel-ltd_00000004287528-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123962</th>\n",
       "      <td>d-herbert-ltd_00000004401371-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123963</th>\n",
       "      <td>h-wright-sons_00000004349558-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123964</th>\n",
       "      <td>pipal-ltd_gbr217113-001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123965 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       id\n",
       "0       design-build-modern-stained-glass_000000044107...\n",
       "1               brent-taxis-cabs_00000005453797-798182001\n",
       "2                 hi-performance-feeds_00000004299041-001\n",
       "3                      maxiflow-drains_00000004249310-001\n",
       "4                        simply-frozen_00000004147330-001\n",
       "...                                                   ...\n",
       "123960            nwt-distribution-ltd_00000004196560-001\n",
       "123961        jkx-executive-travel-ltd_00000004287528-001\n",
       "123962                   d-herbert-ltd_00000004401371-001\n",
       "123963                   h-wright-sons_00000004349558-001\n",
       "123964                            pipal-ltd_gbr217113-001\n",
       "\n",
       "[123965 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_fetcher_per_sector(\"united-kingdom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIOHTTP Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your proxy list from .txt file\n",
    "with open(\"../input_data/proxies_10.txt\") as f:\n",
    "    lines = [line.strip() for line in f.readlines()]\n",
    "    proxy_list = [\"http://{}:{}@{}:{}\".format(line.split(\":\")[2], line.split(\":\")[3], line.split(\":\")[0], line.split(\":\")[1]) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies_in_use = []\n",
    "\n",
    "@contextmanager\n",
    "def allocate_proxy():\n",
    "    \"\"\"Get a free proxy and hold it as in use\"\"\"\n",
    "    available_proxies = [p for p in proxy_list if p not in proxies_in_use] # Select proxies that are not in use\n",
    "    if available_proxies:\n",
    "        proxy = random.choice(available_proxies) \n",
    "    else:\n",
    "        proxy = random.choice(proxy_list) # If there is not an available proxy, we resort to the random.choice method for the entire list.\n",
    "    try:\n",
    "        proxies_in_use.append(proxy)\n",
    "        yield proxy\n",
    "    finally:\n",
    "        proxies_in_use.remove(proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch(url, session):\n",
    "    async with session.get(url,timeout=5000) as response: # not using proxy at the moment\n",
    "        company_id = url.split(\"/\")[-2].lower()+ \"_\" + url.split(\"/\")[-1].split(\".\")[0].lower()\n",
    "        body = await response.text()\n",
    "        soup = BeautifulSoup(body, 'html.parser')\n",
    "        activities = []\n",
    "        size_keywords = 0\n",
    "        # check if you can there is extra information that can be scraped\n",
    "        try:\n",
    "            backend_script = soup.find(\"script\", string=re.compile(r\"^window\\.__NUXT__\"))\n",
    "            # Extract the information between \"keywords: [ ]\"\n",
    "            keywords = re.findall(r'keywords:\\s*\\[(.*?)\\]', '\\n'.join(backend_script), re.DOTALL)\n",
    "            # Remove leading and trailing whitespaces from each keyword\n",
    "            keywords = [keyword.strip() for keyword in keywords]\n",
    "            matches = re.findall(r'id:\"keyword-(\\d+)\"', keywords[1])\n",
    "            indexes = [int(match) for match in matches]\n",
    "            size_keywords = len(indexes)\n",
    "            # Extract the words between \"name:\" and \"}\"\n",
    "            words = [unidecode.unidecode(word.lower()).strip() for word in re.findall(r'name:\"(.*?)\"', keywords[1])]\n",
    "            activities.append(words)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        try:\n",
    "            activities.append([codecs.decode(unidecode.unidecode(activity.text.lower()), 'unicode_escape').strip() for activity in soup.find(\"ul\", class_=\"ep-keywords__list pl-0\").find_all(\"li\")])\n",
    "            flattened_activities = list(set(itertools.chain.from_iterable(activities)))\n",
    "            obtained_size = len(flattened_activities)\n",
    "            # merge the list together separate by |\n",
    "            activities = [' | '.join(flattened_activities)]\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        # Print the extracted words\n",
    "        if activities == []:\n",
    "            return {\"id\": company_id, \"activities\": activities, \"coverage\": 0}\n",
    "        else:\n",
    "            return {\"id\": company_id, \"activities\": activities, \"obtained_size\": obtained_size, \"size_keywords\": size_keywords, \"coverage\": (obtained_size/size_keywords)*100 if size_keywords > 0 else 100}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def bound_fetch(sem, url, session, pbar):\n",
    "    # Getter function with semaphore.\n",
    "    async with sem:\n",
    "        result = await fetch(url, session)\n",
    "        pbar.update(1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run(input_file):\n",
    "    base_url = \"https://www.europages.co.uk/{}/{}.html\"\n",
    "\n",
    "    company_ids = pd.read_csv(input_file)\n",
    "    companies_t = company_ids[\"id\"].tolist()\n",
    "    companies = [company.upper() for company in companies_t]\n",
    "    links = np.array([base_url.format(*company.split(\"_\")) for company in companies])\n",
    "    tasks = []\n",
    "    # create instance of Semaphore\n",
    "    sem = asyncio.Semaphore(1000)\n",
    "    \n",
    "    # Create client session that will ensure we dont open new connection\n",
    "    # per each request.\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # start timer\n",
    "        start_time = time.time()\n",
    "        pbar = tqdm(total=len(links), desc='Scraping EuroPages')    \n",
    "        for link in links:\n",
    "            # pass Semaphore and session to every GET request\n",
    "            task = asyncio.ensure_future(bound_fetch(sem, link, session, pbar))\n",
    "            tasks.append(task)\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    # report final message\n",
    "    print('\\nAll done. Duration: {}s'.format(duration))\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping EuroPages: 100%|██████████| 123965/123965 [56:40<00:00, 36.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All done. Duration: 3400.2306847572327s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "uk_data = await run(\"../input_data/united-kingdom_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_df = pd.DataFrame(uk_data, columns=['id', 'activities'])\n",
    "uk_df.to_csv('../output_data/uk_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping EuroPages: 100%|██████████| 224538/224538 [1:53:48<00:00, 32.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All done. Duration: 6828.539457082748s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "italy_data = await run(\"../input_data/italy_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "italy_df = pd.DataFrame(italy_data, columns=['id', 'activities'])\n",
    "italy_df.to_csv('../output_data/italy_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
